#LyX 2.3 created this file. For more info see http://www.lyx.org/
\lyxformat 544
\begin_document
\begin_header
\save_transient_properties true
\origin unavailable
\textclass article
\begin_preamble
\usepackage{babel}
\newcommand{\indep}{\perp \!\!\! \perp}
\end_preamble
\use_default_options false
\begin_modules
theorems-ams-chap-bytype
\end_modules
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding auto
\fontencoding T1
\font_roman "default" "default"
\font_sans "default" "default"
\font_typewriter "default" "default"
\font_math "auto" "auto"
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100 100
\font_tt_scale 100 100
\use_microtype false
\use_dash_ligatures true
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize 12
\spacing onehalf
\use_hyperref true
\pdf_bookmarks true
\pdf_bookmarksnumbered false
\pdf_bookmarksopen false
\pdf_bookmarksopenlevel 1
\pdf_breaklinks false
\pdf_pdfborder false
\pdf_colorlinks false
\pdf_backref false
\pdf_pdfusetitle true
\papersize default
\use_geometry true
\use_package amsmath 1
\use_package amssymb 0
\use_package cancel 0
\use_package esint 1
\use_package mathdots 0
\use_package mathtools 0
\use_package mhchem 0
\use_package stackrel 0
\use_package stmaryrd 0
\use_package undertilde 0
\cite_engine basic
\cite_engine_type default
\biblio_style plain
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 1
\use_minted 0
\index Index
\shortcut idx
\color #008000
\end_index
\leftmargin 2.5cm
\topmargin 2.5cm
\rightmargin 2.5cm
\bottommargin 2.5cm
\secnumdepth 4
\tocdepth 4
\paragraph_separation indent
\paragraph_indentation default
\is_math_indent 0
\math_numbering_side default
\quotes_style english
\dynamic_quotes 0
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Title
Final Data Science Project (67814) - Analyzing Decision Making in ICUs 
\end_layout

\begin_layout Author
Yuval Roditi, Ben Gofrit
\end_layout

\begin_layout Author
Guided by Prof.
 Michael Beil, Prof.
 Sigal Sviri and Mr.
 Gal Hyams
\end_layout

\begin_layout Section
Abstract
\end_layout

\begin_layout Standard
Sepsis is a deadly critical that accounts for 30% of intensive care admissions
\begin_inset CommandInset citation
LatexCommand cite
key "Sepsis_Mortatlity"
literal "false"

\end_inset

.
 The gold standard for stabilization of patients in septic shock is with
 the drug Norepinephrine (NOR).
 Guidelines specify stabilizing patients around target value of 65 mmHg
 Mean Arterial Pressure (MAP) using NOR
\begin_inset CommandInset citation
LatexCommand cite
key "Gold_standard"
literal "false"

\end_inset

, but do not account for specific patient trajectory and how to do it.
 Previous research showed high variability in sepsis treatment patterns
 
\begin_inset CommandInset citation
LatexCommand cite
key "Sepsis_Treatment_Variability"
literal "false"

\end_inset

.
 
\end_layout

\begin_layout Standard
In this work we show additional evidence for the variability in sepsis treatment
 across different Intensive Care Units (ICUs) in the same hospital using
 the MIMIC-IV
\begin_inset CommandInset citation
LatexCommand cite
key "MIMIC-IV"
literal "false"

\end_inset

 database.
 In particular, we show that for 
\begin_inset Formula $\unitfrac{6}{8}$
\end_inset

 of MAP categories (bins) there exists a signifciant 
\begin_inset Formula $\left(p<0.05\right)$
\end_inset

 difference in mean NOR dosage between the Medical and Surgical ICUs (MICU,
 SICU).
 Given those differences, we looked to harness Offline Reinforcement Learning
 to establish a NOR dosage optimal policy that is seeking to stabilize patients
 around the recommended target value for MAP (65 mmHg).
\end_layout

\begin_layout Standard
Offline RL models for sepsis treatment have been developed in the past,
 most knowingly in 2018 work published by Komorowski et al 
\begin_inset CommandInset citation
LatexCommand cite
key "Nature_Komorowski"
literal "false"

\end_inset

.
 However, those works focused on limiting mortatlity (long-term reward)
 and not short-term patient stabilization.
 Our model uses a simplified state space, which consists only of binned
 MAP measurements.
\end_layout

\begin_layout Standard
Training the model on MIMIC did not produce explainable results, due to
 the potentially and variable large temporal difference between observations
 (MAP measurements) and the actions (NOR doses).
 However, when trained with data from the eICU database
\begin_inset CommandInset citation
LatexCommand cite
key "eICU"
literal "false"

\end_inset

, which have a higher temporal resolution (MAP every 5 minutes instead of
 every hour in MIMC), the model produced much more reasonble results, which
 had a higher Mutual Information between MAP value and dosage.
 Creating a reliable MAP stabilizing RL-model holds potential for improving
 the treatment given to sepsis patients in ICUs.
\end_layout

\begin_layout Section
Introduction
\end_layout

\begin_layout Subsection
Medical Background and Past Works 
\end_layout

\begin_layout Standard
Sepsis is a life-threating condition that may arise as a response to an
 infection.
 It often requires ICU admission.
 Hence, it accounts for 30% of ICU admissions
\begin_inset CommandInset citation
LatexCommand cite
key "ICU_SEPS_STATS"
literal "false"

\end_inset

.
 sepsis will often be charactherized with a drop in blood pressure, which
 in turn will reduce the blood supplied to vital organs.
 It is a critical condition, with an estimated mortality rate of 38% 
\begin_inset CommandInset citation
LatexCommand cite
key "Sepsis_Mortatlity"
literal "false"

\end_inset

.
 
\end_layout

\begin_layout Standard
Norepinephrine (NOR)
\begin_inset Foot
status open

\begin_layout Plain Layout
NOR for short, may sometimes be refered to as noradrenaline (NA, NE)
\end_layout

\end_inset

 is a drug that constricts the blood vessels in the body, thus increasing
 the blood pressure (drugs with this property are known as Vasopressors).
 NOR is considered to be the gold standard when treating sepsis, with a
 
\color black
goal stabilization a parient's Mean Arterial Pressure (MAP
\color inherit

\begin_inset Foot
status open

\begin_layout Plain Layout
Mean Arterial Pressure is a measure of the average pressure in the arteries
 during one cardiac cycle.
 Estimated from the Systolic and Diastolic BP: MAP = 
\begin_inset Formula $\unitfrac{(2\cdot\ diastolic\ BP)+systolic\ BP]}{3}$
\end_inset


\end_layout

\end_inset


\color black
) near the target value of 65 mmHg.

\color inherit
 
\begin_inset CommandInset citation
LatexCommand cite
key "Gold_standard"
literal "false"

\end_inset


\end_layout

\begin_layout Standard
However, apart from this rule of thumb, there are no patient-level guidelines
 to instruct treatment for a specific patient.
 For example, even though there is an explicit target goal MAP, there is
 no regards for the specific patient's MAP trajectory to reach that goal.
 Thus, it shoud come as no surprise that there is a high variablity in sepsis
 treatment patterns 
\begin_inset CommandInset citation
LatexCommand cite
key "Sepsis_Treatment_Variability"
literal "false"

\end_inset


\end_layout

\begin_layout Standard
It is only natural that attempts at harnessing Artifcial Intelligence for
 this task will come about.
 Such was the vast work published in 2018 Nature Medicine (
\shape italic
The Artificial Intelligence Clinician learns optimal treatment strategies
 for sepsis in intensive care,
\shape default
 
\series bold
Komorowski et al
\series default
 
\begin_inset CommandInset citation
LatexCommand cite
key "Nature_Komorowski"
literal "false"

\end_inset

).
 In this work, a Reinforcment Learning (see 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Reinforcement-Learning"
plural "false"
caps "false"
noprefix "false"

\end_inset

) based model was developed to suggest optimal treatment patterns: mainly
 doses of Vasopressors and IV fluids.
 The target of the model was to reduce the patients' mortality as much as
 possible, be it in the ICU or 90-day mortatlity.
 The model included a set of 48 patient variables: from demographics, to
 vitals signs and labratory results.
 
\end_layout

\begin_layout Standard
Although promisingly claiming: 
\begin_inset Quotes eld
\end_inset


\shape italic
mortality was lowest in patients for whom clinicians’ actual doses matched
 the AI decisions
\begin_inset Quotes erd
\end_inset

, 
\shape default
the work raised criticism and concern regarding applying the model in actual
 clincal use.
 For example in the following figure taken from the manuscript :
\begin_inset Newline newline
\end_inset


\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename 2018_policy_boxplots.png
	scale 40

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Estimated Policy Values boxplots comparing the AI model with clinicans,
 zero-drug policy and random policy 
\begin_inset CommandInset citation
LatexCommand cite
key "Nature_Komorowski"
literal "false"

\end_inset

.
\end_layout

\end_inset


\end_layout

\end_inset

 it is apparent that the AI preformed better than human clinicians.
 However, it is alarming to see that on average, 
\series bold
no interference policy was actually better, 
\series default
in terms of estimated policy value,
\series bold
 
\series default
than both the AI and the human clincian's policy.
\end_layout

\begin_layout Standard
This issue, as well as a recreation of the results and comparing the AI's
 suggestions to clincian's descisions for indvidual patient's trajectories
 are discussed in great lengths in the 2019 review by Jeter, Josef, Shashikumar,
 & Nemati 
\begin_inset CommandInset citation
LatexCommand cite
key "clinician_review"
literal "false"

\end_inset

 .
 One crucial keypoint of criticism discussed by Jeter et al is the sole
 focus of the 2018 work on long term rewards: hospital and 90-days morbidity.
 It disregarded the importance of intermediate rewards in the short term,
 in particular stablizing a patient's vitals and mainting their MAP in the
 recommended values, which bares more resemblance to a clinican's methodology
 in decsion making.
 
\end_layout

\begin_layout Subsection
Data
\end_layout

\begin_layout Standard
The abovementioned works were trained on MIMIC-III (Medical Information
 Mart for Intensive Care) - a publicly available database of patients admitted
 to the Beth Israel Deaconess Medical Center (BIDMC) in Boston, USA, published
 in 2016
\begin_inset CommandInset citation
LatexCommand cite
key "MIMIC-III"
literal "false"

\end_inset

.
 In March 2021 a new version of MIMC was released - MIMIC-IV.
 It contains deidentified data of 50,048 patients admitted to an intensive
 care unit 
\begin_inset CommandInset citation
LatexCommand cite
key "MIMIC-IV"
literal "false"

\end_inset

.
 
\end_layout

\begin_layout Standard
In addition, we used the eICU Collaborative Research Database.
 It is a large, comprehensive dataset of critical care data collected from
 over 200 ICUs at multiple hospitals across the United States, made available
 by Philips Healthcare.
 The database covers patients who were admitted to critical care units in
 2014 and 2015, and was made publicly available at 2018 
\begin_inset CommandInset citation
LatexCommand cite
key "eICU"
literal "false"

\end_inset

.
\end_layout

\begin_layout Subsection
Objectives in our work
\end_layout

\begin_layout Standard
Our overall goal in this work was to understand desicion making in the ICU.
 The main objective is to model sequential decision-making, i.e.
 time-dependent trajectories of decisions.
 As a first step, we wanted to give additional evidence for the lack of
 uniform sepsis treatment patterns in the ICU.
 Secondly we sought to create a simple, interpretablemodel for decision
 making in the task of stabilizing a sepsis patient to a given Mean Arterial
 Blood Pressure (MAP) value.
 
\end_layout

\begin_layout Subsubsection
Treatmeant Variability Assessment between ICU units
\end_layout

\begin_layout Standard
As mentioned above, evidence regarding the variability in treatment patterns
 has been published, like the work preformed by Bray et al (2020)
\begin_inset CommandInset citation
LatexCommand cite
key "Sepsis_Treatment_Variability"
literal "false"

\end_inset

.
 This work analyzed the variability by comparing sepsis treatment protocols
 in different medical units in the UK's healthcare system (NHS Trusts).
 Considerable variation was found: from the factors that define a patient
 as 
\begin_inset Quotes eld
\end_inset

high risk
\begin_inset Quotes erd
\end_inset

, to treatment steps recommended in a patient's pathway.
\end_layout

\begin_layout Standard
Even though MIMIC does not contain any identifying data on which clinician
 gave a specific treatment, we seeked to assess the sepsis treatment variablity
 evident in the data.
 A possible mediator was to look at the treatment variability across between
 different ICU units.
 Two particular units interesed proposed by our project guides were the
 Medical ICU (MICU) and the Surgical ICU (SICU).
 Those two units differ in both their patient populations (SICU hosts patients
 before / after surgeries) and the training of medical staff (medicine vs
 surgery / anaesthesia).
\end_layout

\begin_layout Standard
We sought to find evidence for differences in treatment decisions - which
 we limited to the NOR dosage that patients with similar MAP recieved in
 the different units.
 Results and methodoloy are detailed in section 
\begin_inset CommandInset ref
LatexCommand vref
reference "subsec:SICU---MICU"
plural "false"
caps "false"
noprefix "false"

\end_inset

.
\end_layout

\begin_layout Subsubsection
Basic MAP Stabilization Recommendation Model
\end_layout

\begin_layout Standard
We sought to create a simple interpreteble Reinforcement Learning model
 to recommend short term MAP stabilization of sepsis patients.
 Unlike the 2018 Nature's Clinician, this model will not seek to minimize
 long-term morbidity, but will look to keep a sepsis patient's MAP value
 at a stable range.
 
\end_layout

\begin_layout Subsection
Mathematical Background
\end_layout

\begin_layout Subsubsection
Permutations Test
\end_layout

\begin_layout Standard
Permutations Test is a statistical test useds to determine whether two observati
ons were drawn from the same distribution.
 It is a non-parametric approach and does not require knowing the distribution
 of the data.
 The test is performed by randomly taking two groups of the distribution
 and computing the test statistic (e.g difference of means) with shuffeled
 labels.
 The p-value is calculated as the fraction of randomly labeled iterations
 that had a more extreme test statistic value than that of the original
 dataset.
\end_layout

\begin_layout Subsubsection
Kolmogorov Smoirnov Test
\end_layout

\begin_layout Standard
Additional non-parametric test to determine whether two samples come from
 the same underlying distribution.
 The KST works by calculating CDFs (Cumulative Distribution Function) for
 the two samples and comparing the maximal difference between them.
 The maximal difference is known as the KS statistic: 
\begin_inset Formula $D_{KS}=\sup_{x}\left|F\left(x\right)-G\left(x\right)\right|$
\end_inset

, which can be used to generate p-values for the hypothesis 
\begin_inset Formula $H_{0}:F=G$
\end_inset

 against 
\begin_inset Formula $H_{1}:F\neq G$
\end_inset

.
\end_layout

\begin_layout Subsubsection
Reinforcement Learning
\begin_inset CommandInset label
LatexCommand label
name "subsec:Reinforcement-Learning"

\end_inset


\end_layout

\begin_layout Standard
Reinforcement Learning (RNL) is a branch of Machine Learning, which corresponds
 to a set of problems and solutions.
 The key factors which distinguish it from Supervised and Unsupervised Learning
 is that in RNL, an agent interacts with the enviroment in a dynamic way,
 looking to optimzie a reward function.
 A usual RNL process follows the procedure:
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename pasted2.png
	scale 40

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
The agent–environment interaction in reinforcement learning.
 Taken from Sutton 
\begin_inset Formula $\&$
\end_inset

 Barto, 2018 
\begin_inset CommandInset citation
LatexCommand cite
key "RL Sutton Barto"
literal "false"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
During the training phase of RNL, the agent learns which action to take
 at a given state, to maximize the reward.
\begin_inset Newline newline
\end_inset

 We will notate the set of all possible actions with a capital 
\begin_inset Formula $\mathcal{A},$
\end_inset

 and set of all possible states -
\begin_inset Formula $\mathcal{S}$
\end_inset

.
 A few important definitions for our context (taken from 
\begin_inset CommandInset citation
LatexCommand cite
key "RL Sutton Barto"
literal "false"

\end_inset

) are:
\end_layout

\begin_layout Definition
\begin_inset Argument 1
status open

\begin_layout Plain Layout
Policy function
\end_layout

\end_inset

 a function that dictates which action should be taken at a given state,
 denoted as 
\begin_inset Formula $\pi:\mathcal{S}\rightarrow\mathcal{A}$
\end_inset

.
 
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Definition
\begin_inset Argument 1
status open

\begin_layout Plain Layout
Value function
\end_layout

\end_inset

 an estimation of the expected cumaltive reward if one followed the policy
 
\begin_inset Formula $\pi$
\end_inset

 starting from state 
\begin_inset Formula $s\in\mathcal{S}.$
\end_inset


\begin_inset Formula 
\[
v_{\pi}\left(s\right)=E_{\pi}\left(\sum_{k=0}^{\infty}\gamma^{k}R_{t+k+1}\mid S_{t}=s\right)
\]

\end_inset

 where 
\begin_inset Formula $E_{\pi}$
\end_inset

 is to emphasize that the expected value is taken with regards to following
 policy 
\begin_inset Formula $\pi$
\end_inset

 from state s.
 
\begin_inset Formula $R_{k}$
\end_inset

 is the return recieved at the 
\begin_inset Formula $k$
\end_inset

'th step of the process, and 
\begin_inset Formula $\gamma\in\left(0,1\right)$
\end_inset

 is a discount factor - a hyperparameter used to discount the value of longer
 termed reward which ensures the convergence of the series).
 
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Definition
\begin_inset Argument 1
status open

\begin_layout Plain Layout
Action-Value function (Q-Function)
\end_layout

\end_inset

 A function which denotes the value of taking action 
\begin_inset Formula $a\in\mathcal{A}$
\end_inset

 at state 
\begin_inset Formula $s\in\mathcal{S}$
\end_inset

 and following policy 
\begin_inset Formula $\pi$
\end_inset

 thereafter:
\begin_inset Formula 
\[
q_{\pi}\left(s,a\right)=E_{\pi}\left(\sum_{k=0}^{\infty}\gamma^{k}R_{t+k+1}\mid S_{t}=s,A_{t}=a\right)
\]

\end_inset


\end_layout

\begin_layout Section
Results
\end_layout

\begin_layout Subsection
SICU - MICU Comparision 
\begin_inset CommandInset label
LatexCommand label
name "subsec:SICU---MICU"

\end_inset


\end_layout

\begin_layout Standard
We divided the inputs data to groups (binning) according to their last blood
 pressure measurement before receiving the Norepinephrine:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
MAP\ RANGES=\left[\underset{b_{0}}{\underbrace{(0,49)}},(50,59),\ldots,(80,89),\underset{b_{7}}{\underbrace{(90,200)}}\right]
\]

\end_inset


\end_layout

\begin_layout Standard
After doing so, we want to check for each group the hypothesis that the
 treatment will be the same across different units, against the conjecture
 that treatment varies.
 Let 
\begin_inset Formula $\mu_{M,b_{j}}$
\end_inset

 denote the expected value of NOR dose in the Medical ICU unit for the group
 with bp in the range denoted as 
\begin_inset Formula $b_{j}$
\end_inset

, and likewise for 
\begin_inset Formula $\mu_{S,b_{j}}$
\end_inset

(for Surgical ICU).
 
\end_layout

\begin_layout Standard
We tested for each of the 
\begin_inset Formula $8$
\end_inset

 hypothesis separately:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
H_{0} & :\mu_{M,b_{j}}=\mu_{S,b_{j}}\\
H_{1} & :\mu_{M,b_{j}}\neq\mu_{S,b_{j}}
\end{align*}

\end_inset


\end_layout

\begin_layout Subsubsection
Permutations Test
\end_layout

\begin_layout Standard
We started with a baseline permutation test (15,000 permutations), which
 provided the following results:
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Formula 
\[
\begin{tabular}{lllllllll}
  &  0  &  1  &  2  &  3  &  4  &  5  &  6  &  7 \\
 bp\_range  &  (0, 49)  &  (50, 59)  &  (60, 64)  &  (65, 69)  &  (70, 74)  &  (75, 79)  &  (80, 89)  &  (90, 200) \\
 p\_val  &  0.825667  &  0.0012  &  0.138  &  0.012733  &  0.0116  &  0.010533  &  0.003933  &  0.0002 \\
 is pval < 0.05  &  False  &  \boldsymbol{True}  &  False  &  \boldsymbol{True}  &  \boldsymbol{True}  &  \boldsymbol{True}  &  \boldsymbol{True}  &  \boldsymbol{True} 
\end{tabular}
\]

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
P-Values for each bin testing 
\begin_inset Formula $H_{0}:\mu_{M,b_{j}}=\mu_{S,b_{j}}$
\end_inset

against 
\begin_inset Formula $H_{1}:\mu_{M,b_{j}}\neq\mu_{S,b_{j}}$
\end_inset

 using 15,000 permutations.
 See Notebook 
\begin_inset Quotes eld
\end_inset

permutation_test.ipynb
\begin_inset Quotes erd
\end_inset

 for reproduction .
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
It is evident that in almost all groups there has been a significant difference
 between the expected NOR dose between the units for patients with the same
 MAP values.
 This is true for all bp ranges apart from two: 
\begin_inset Formula $(0,49)$
\end_inset

 which doesn't have enough samples for statistically significant p-value,
 and 
\begin_inset Formula $(60,64)$
\end_inset

,, which is very close to the target value.
\end_layout

\begin_layout Subsubsection
KST comparision
\end_layout

\begin_layout Standard
Following is a comparision of the PDF for each of MAP bins, alongside their
 KST p-values.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename histogram_per_bp.jpeg
	scale 50

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Probability Density Function of the original NOR rate in each BP group,
 with division to MICU and SICU, alongside KST p-val and the amount of samples
 in each group.
 For reproduction - run ks_test.ipynb notebook
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
Similarly to the p-values generated using the permutation test, in most
 groups 
\begin_inset Formula $p-val<0.05,$
\end_inset

 evident that there is a significant difference in the means of the NOR
 dosage given to patients with similar BP between the units.
\end_layout

\begin_layout Standard
Additional resolution achieved in this method is the shape of the distributions
 we see that the peak of the distribution of MICU tends to be lower than
 SICU, which indicates a higher range of dose values given by the doctors
 in MICU (In SICU doctors tend to give dosage which is close to 0.05 across
 all groups).
\end_layout

\begin_layout Standard
Two groups that did not have a significant difference are the first group
 (0-49) which doesn't contain enough samples for statistical significance,
 and two groups near the target area of 65 - 
\begin_inset Formula $\left(60-64\right)$
\end_inset

 and 
\begin_inset Formula $\left(75-79\right).$
\end_inset

 
\end_layout

\begin_layout Standard
In both units, the dosage variabilty changes according to the prior BP measureme
nt.
 Around the edges the variability is higher, while in the 50-90 portion
 the variability is lower.
 This could explain the high p-value for the first bin (0-49).
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename nor_dosage_per_bp_mimic.jpeg
	scale 50

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Illustration of the dosage variability per prior BP in the MIMIC database.
 For reproduction: 'databases_variability.ipynb' 
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Reinforcement Learning
\end_layout

\begin_layout Subsubsection
Setting and Terminology
\end_layout

\begin_layout Standard
We've implemented the RNL framework for our task at hand: keeping the patient's
 MAP value at a prespecified target MAP.
 The formulation is natural for this problem:
\end_layout

\begin_layout Itemize
Agent - the caretaker, which decides which action to take.
 
\end_layout

\begin_layout Itemize
States - represented as the MAP bin of the patient.
 We defined the bins like before: 
\begin_inset Formula $\mathcal{S}=\left[\underset{b_{0}}{\underbrace{(0,49)}},(50,59),\ldots,(80,89),\underset{b_{7}}{\underbrace{(90,200)}}\right].$
\end_inset


\end_layout

\begin_layout Itemize
Actions - NOR dosage.
 In order to define a finite set of possible doses, we decided to limit
 the set of possible actions to 
\begin_inset Formula $\mathcal{A}=\left\{ 0,0.01,\ldots0.4\right\} $
\end_inset


\end_layout

\begin_layout Itemize
Reward function - we decided to define ahead of training the goal of maximizing
 the amount of time a patient spents in the recommended area of 65 MAP.
 Therfore, the reward function was defined to be the negative square distance
 from 65 
\begin_inset Formula $R_{t}=-\left\Vert s_{t}-65\right\Vert ^{2}$
\end_inset

 (negative since we are looking to maximze the reward function in RNL algorithms
).
\end_layout

\begin_layout Itemize
Policy - determines which NOR dosage to give to a patient at a given state.
 The agent's goal is to learn the optimal policy in terms of the cumlative
 reward generated from the reward function.
 
\end_layout

\begin_layout Itemize
Episode - The trajectory of states, actions and rewards for a single patient.
 Starting from his arrival to the ICU (or the initial data point available)
 to the last.
 
\end_layout

\begin_layout Subsubsection
Offline RNL
\end_layout

\begin_layout Standard
In classic RNL setting, the agent has the freedom to knowingly make explorative
 non-optimal desicions with the goal of widening its knowledge on the enviroment.
 For our task and data this is neither possible (since we have a static
 dataset) nor ethical (doing so would mean knowingly taking wrong choices
 in patient treatment).
 The solution is Offline RNL - the agent learns 
\shape italic
off-policy,
\shape default
 from dataset 
\begin_inset Formula $\mathcal{D}$
\end_inset

 that was collected prior training according to
\shape italic
 any 
\shape default
policy, and does not interact with the enviroment in an online setting 
\begin_inset CommandInset citation
LatexCommand cite
key "offline_RNL"
literal "false"

\end_inset

.
 
\end_layout

\begin_layout Subsubsection
Markovian Assumption
\end_layout

\begin_layout Standard
As is the case in many RNL based models, our model assumes the decision
 process represented in the data adheres to the Markov property.
 This assumptios fits the reality of decisions about NOR in shock patients
 well.
 The caretaker is mainly, if not exclusively interested in adjusting the
 blood pressure with a drug (NOR) that does not accumulate.
\end_layout

\begin_layout Standard
Formally, given a trajectory of states (i.e MAP values) 
\begin_inset Formula $s_{1},\ldots,s_{t},$
\end_inset

and an action (NOR doseage) 
\begin_inset Formula $a_{t}\in\left\{ 0,0.01,\ldots,0.4\right\} ,$
\end_inset

the next state 
\begin_inset Formula $s_{t+1}$
\end_inset

 will depend solely on the action and the previous state.
 That is, the transition function 
\begin_inset Formula $\tau:\mathcal{S}\times\mathcal{A}\rightarrow\mathcal{S}$
\end_inset

 satifies:
\begin_inset Formula 
\[
\tau\left(s_{t+1},a_{t}\mid s_{0},\ldots,s_{t}\right)=\tau\left(s_{t+1},a_{t}\mid s_{t}\right)
\]

\end_inset


\end_layout

\begin_layout Subsubsection
Patient Simulator and Transition Probabilites Estimation
\end_layout

\begin_layout Standard
Our enviroment was repesented via a 
\series bold
\shape italic
Patient Simulator
\series default
\shape default
 class.
 Each instance of this class has a MAP state, and can be interacted with
 via a 
\shape italic
give_dose
\shape default
 API .
 
\shape italic
Give_dose
\shape default
 will change the patient's MAP according to an estimation of the transition
 probabilities - 
\begin_inset Formula $\hat{\tau}.$
\end_inset

 A natural way to estimate 
\begin_inset Formula $\hat{\tau}$
\end_inset

 is by sampling the training data after conditioning.
 We'll estimate 
\begin_inset Formula $\hat{\tau}$
\end_inset

 as the marginal probability of a state 
\begin_inset Formula $s_{t+1}$
\end_inset

 given the previous 
\begin_inset Formula $s_{t}$
\end_inset

 and action 
\begin_inset Formula $a_{t}$
\end_inset

.
 Formally, given dataset 
\begin_inset Formula $\mathcal{D},$
\end_inset

 define the subsets: 
\end_layout

\begin_layout Definition
\begin_inset Formula $\mathcal{D}_{\ast\mid s_{t},a_{t}}$
\end_inset

- All entries in the dataset where action 
\begin_inset Formula $a_{t}$
\end_inset

 was taken following the state 
\begin_inset Formula $s_{t}.$
\end_inset


\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Definition
\begin_inset Formula $\mathcal{D}_{s_{t+1}\mid s_{t},a_{t}}$
\end_inset

- Entries in the dataset that are equal to 
\begin_inset Formula $s_{t+1}$
\end_inset

, and followed the tuple 
\begin_inset Formula $\left(s_{t},a_{t}\right)$
\end_inset

.
\end_layout

\begin_layout Standard
The natural estimator for the transition probability will be:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\hat{\tau}=\left(s_{t+1},a_{t}\mid s_{t}\right)=\frac{\left|\mathcal{D}_{s_{t+1}\mid s_{t},a_{t}}\right|}{\left|\mathcal{D}_{\ast\mid s_{t},a_{t}}\right|}
\]

\end_inset


\end_layout

\begin_layout Remark
This estimator is a generalization of the MLE for transition matrix in a
 classic Markov Chain (without actions).
 It can be proven that in a Markov Chain model 
\begin_inset Formula $X_{1},\ldots,X_{n}$
\end_inset

 where one looks to find the transition probability 
\begin_inset Formula $p_{ij}=P\left(X_{t+1}=j\mid X_{t}=i\right),$
\end_inset

the MLE estimator is 
\begin_inset Formula $\hat{p}_{ij}=\frac{n_{ij}}{\sum_{j}n_{ij}}$
\end_inset

, where 
\begin_inset Formula $n_{ij}$
\end_inset

 is the number of instances of the tuple of states 
\begin_inset Formula $\left(X_{i},X_{j}\right)$
\end_inset

 across trajectories, and the summation in the denominator is across all
 possible states 
\begin_inset CommandInset citation
LatexCommand cite
key "markov_lme"
literal "false"

\end_inset

.
 If we were to define a new state set from the cartesian product of the
 states and actions sets 
\begin_inset Formula $\mathcal{S}^{\prime}:=\left\{ \left(s,a\right)\in\mathcal{S}\times\mathcal{A}\right\} ,$
\end_inset

 our 
\begin_inset Formula $\hat{\tau}$
\end_inset

 will converge with the MLE estimator for the transition probability in
 that model.
\end_layout

\begin_layout Standard
In practice, 
\series bold
\shape italic
Patient Simulator 
\series default
\shape default
does not calculate 
\begin_inset Formula $\hat{\tau}$
\end_inset

 explicitly.
 It samples the next state from the group 
\begin_inset Formula $\mathcal{D}_{\ast\mid s_{t},a_{t}}$
\end_inset

, which implies the transition probability 
\begin_inset Formula $\hat{\tau}$
\end_inset

 over the states.
 Therefore, states for which 
\begin_inset Formula $\mathcal{D}_{s_{t+1}\mid s_{t},a_{t}}=\emptyset$
\end_inset

 will have zero probability.
 
\end_layout

\begin_layout Subsubsection
Initialization and Termination of Epsiodes
\end_layout

\begin_layout Standard
Two important cases left to be considered were how to start and end an episode
 in the patient simulator.
 In order to be as close to the data as possible, we decided to sample the
 starting point randomly from all states which appear as the starting point
 for a patient in 
\begin_inset Formula $\mathcal{D}$
\end_inset

.
 Likewise, when we sample using the transition function 
\begin_inset Formula $\hat{\tau}$
\end_inset

 a state 
\begin_inset Formula $s_{t+1}$
\end_inset

 which happens to be a terminal state for a particular patient, we will
 terminate the episode.
 
\end_layout

\begin_layout Subsubsection
Model Training Algorithm
\end_layout

\begin_layout Standard
We choose to train our RNL model using Q-Learning Monte Carlo algorithm.
 The main idea of the algorithm is to iterativly estimate the state-action
 function 
\begin_inset Formula $q_{\pi}\left(s,a\right)$
\end_inset

, calculate the optimal policy 
\begin_inset Formula $\pi$
\end_inset

 using it, play an episode using the policy 
\begin_inset Formula $\pi,$
\end_inset

 and update the 
\begin_inset Formula $q$
\end_inset

 function using the newly aquired data from the episode.
 We also used the 
\shape italic
first-visit variation 
\shape default
of the algorithm, which is an optimization variant that skips re-evaluating
 the same state-action pairs in the same episode (for effiency).
 This variation is widely studied, and is referenced in page 128 in 
\begin_inset CommandInset citation
LatexCommand cite
key "RL Sutton Barto"
literal "false"

\end_inset

.
\begin_inset Newline newline
\end_inset

The algorithm assumes (and takes as an input) an episode simulator which
 is able to generate a series of states, action and following rewards :
 
\begin_inset Formula $\left\{ \left(s_{t},a_{t},r_{t}\right)\right\} _{t=0}^{k}$
\end_inset

 (
\begin_inset Formula $s_{k}$
\end_inset

 being the terminal state).
 In our setting, the Episode simulator is implemented via the class 
\shape italic
Patient Simulator.
 
\shape default
Follows is a psedo-code of the training algorithm:
\end_layout

\begin_layout Standard
\begin_inset Float algorithm
placement H
wide false
sideways false
status open

\begin_layout Plain Layout

\series bold
Input
\series default
: Episode Simulator, N-Episodes (integer)
\end_layout

\begin_layout Plain Layout

\series bold
Output:
\series default
 Optimal Policy 
\begin_inset Formula $\pi^{\ast}$
\end_inset

 and Estimated Value function for that policy 
\begin_inset Formula $\hat{v}_{\pi^{\ast}}$
\end_inset

 
\end_layout

\begin_layout Enumerate

\series bold
Initialization: 
\end_layout

\begin_deeper
\begin_layout Enumerate
Initialize 
\begin_inset Formula $\pi_{0}$
\end_inset

 randomly.
\end_layout

\begin_layout Enumerate
Initialize Q function that evaluates each state-action q value to be 0:
 
\begin_inset Formula 
\[
q=\left\{ \left(s,a\right)\rightarrow0\mid\left(s,a\right)\in\mathcal{S}\times\mathcal{A}\right\} 
\]

\end_inset

 
\end_layout

\begin_layout Enumerate
Initialize empty returns hashtable, that maps each pair to a list of returns
 produced from this pair.
\begin_inset Formula 
\[
\boldsymbol{returns}=\left\{ \left(s,a\right)\rightarrow\left[\ldots\right]\mid\left(s,a\right)\in\mathcal{S}\times\mathcal{A}\right\} 
\]

\end_inset


\end_layout

\end_deeper
\begin_layout Enumerate

\series bold
Iteration:
\series default
 For each 
\begin_inset Formula $i=1,...,N-Episodes$
\end_inset

:
\end_layout

\begin_deeper
\begin_layout Enumerate
Initialize an empty hashtable of seen_before_states 
\begin_inset Formula $\left\{ \ldots\right\} .$
\end_inset


\end_layout

\begin_layout Enumerate
Generate a series of states, actions and rewards 
\begin_inset Formula $\left\{ \left(s_{t},a_{t},r_{t}\right)\right\} _{t=0}^{k}$
\end_inset

 via the Episode Simulator with policy 
\begin_inset Formula $\pi_{i-1}$
\end_inset

.
\end_layout

\begin_layout Enumerate
Iterate over the epsiode's trajectory - For 
\begin_inset Formula $t=0,\ldots,k$
\end_inset

:
\end_layout

\begin_deeper
\begin_layout Enumerate
Check if the pair 
\begin_inset Formula $\left(s_{t},a_{t}\right)$
\end_inset


\begin_inset Formula $\in$
\end_inset

seen_before_states.
 If it has been seen move to next t.
 Else add 
\begin_inset Formula $\left(s_{t},a_{t}\right)$
\end_inset

 to seen_before_states .
\end_layout

\begin_layout Enumerate
Add 
\begin_inset Formula $r_{t}$
\end_inset

 to the returns hashtable list that matches the pair 
\begin_inset Formula $\left(s_{t},a_{t}\right)$
\end_inset


\end_layout

\begin_layout Enumerate
Update 
\begin_inset Formula $q\left(s,a\right)$
\end_inset

 to be the average of returns list that matched the pair 
\begin_inset Formula $\left(s_{t},a_{t}\right)$
\end_inset

 including return 
\begin_inset Formula $r_{t}$
\end_inset

.
\end_layout

\end_deeper
\begin_layout Enumerate
Update the policy 
\begin_inset Formula $\pi_{i}\left(s\right)=arg\max_{a\in\mathcal{A}}\left\{ q\left(s,a\right)\right\} .$
\end_inset


\end_layout

\end_deeper
\begin_layout Enumerate

\series bold
Termination
\series default
: Final policy is 
\begin_inset Formula $\pi_{N-episodes}.$
\end_inset

 State-value function can be inferred using 
\begin_inset Formula $q_{\pi_{N-episodes}}:$
\end_inset

 
\begin_inset Formula $v_{\pi_{N-episodes}}\left(s\right)=\max\left\{ q\left(s,a\right)\mid a\in\mathcal{A}\right\} $
\end_inset

.
 Algorith returns the pair: 
\begin_inset Formula $\pi_{N-episodes},$
\end_inset


\begin_inset Formula $v_{\pi_{N-episodes}}$
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
First Visit Q-Learning Monte Carlo 
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
We used an existing implementation by Colin Skow
\begin_inset CommandInset citation
LatexCommand cite
key "skow-github"
literal "false"

\end_inset

 and fitted it to our settings' needs.
\end_layout

\begin_layout Subsubsection
Results From Training the Model
\end_layout

\begin_layout Standard
After filtering the MIMIC data to clear decisions (see 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Decisions-Filter"
plural "false"
caps "false"
noprefix "false"

\end_inset

) we ran the Q-Learning Monte Carlo Algorithm for 1000 episodes, and ploted
 the resulting policy 
\begin_inset Formula $\&$
\end_inset

 value functions:
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename expected_bp_mimicjpeg.jpeg
	scale 45

\end_inset


\begin_inset Graphics
	filename MIMIC_BP_POLICY_RNL.jpeg
	scale 45

\end_inset


\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Caption Standard

\begin_layout Plain Layout
MIMIC trained: Estimated BP Value function after 
\begin_inset Formula $1,000$
\end_inset

 iterations, with discount factor 
\begin_inset Formula $\gamma=0.9$
\end_inset

.
 For reproduciton code see rnl_resuls.ipynb notebook.
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
The policy appears to be random.
 The Estimated category value has more order to it, reflecting the reward
 function.
 The lower bins have more value since there is a higher probability to get
 to the target of 65, while lowset estimated bin value is around 80-90,
 reflecting areas were the probability to go back to the target value is
 the lowest.
 
\end_layout

\begin_layout Subsection
eICU RNL
\end_layout

\begin_layout Standard
The eICU offers a higher time resolution of MAP measurements.
 While patients in MIMIC have an average of one measurement per hour, in
 the eICU time resolution is every five minutes.
 As the number of samples available in the interval between each NOR injection
 is larger, the variance before each NOR injection is smaller:
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename hist_before_injection_eicu.jpeg
	scale 45

\end_inset


\begin_inset Graphics
	filename hist_before_injection_mimic.jpeg
	scale 45

\end_inset


\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Caption Standard

\begin_layout Plain Layout
Histogram of BPs Prior to NOR injection, comparision of MIMIC and eICU.
 Both have a gaussian bell curve with similar means (marked in red).
 However the variance in eICU is smaller, which hints it may be more suitable
 for learning using simulation in the RNL setting.
 For reproducion run: 'databases_variability.ipynb'
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
This encouraged us to process the eICU data to fit our RNL framework as
 well, and train our model using this data.
\end_layout

\begin_layout Standard
The results were more plausible than those obtained from MIMIC:
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename eICU_Expected_value.jpeg
	scale 45

\end_inset


\begin_inset Graphics
	filename eICU_Policy.jpeg
	scale 45

\end_inset


\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Caption Standard

\begin_layout Plain Layout
eICU trained: Estimated BP Value function after 
\begin_inset Formula $1,000$
\end_inset

 iterations, with discount factor 
\begin_inset Formula $\gamma=0.9$
\end_inset

.
 For reproduciton code see rnl_results.ipynb notebook
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
It looks that the policy that was obatined with eICU is more reasonable
 than MIMIC: Recommends higher dosage in the low BP range, and as we get
 close to 65 lower doses.
 The exception is the right handside of the BP ranges, where the model suggests
 higher doses.
 This is unreasonable and may be due to symmetric reward function chosen
 (see 
\begin_inset CommandInset ref
LatexCommand ref
reference "enu:Reward-function:-Our"
plural "false"
caps "false"
noprefix "false"

\end_inset

).
\end_layout

\begin_layout Subsubsection
Evaluation Metric 
\end_layout

\begin_layout Standard
While it is clear to the observer , it is hard to quantify the 
\shape italic

\begin_inset Quotes eld
\end_inset

reasonablity
\begin_inset Quotes erd
\end_inset

 
\shape default
of the eICU policy vs the MIMIC.
 One attempt at quantifiying this is to look at the relation between the
 BP range and the recommended dosage.
 We would expect that a 
\begin_inset Quotes eld
\end_inset

good
\begin_inset Quotes erd
\end_inset

 policy will be closely related to the BP value observed.
 However, the relation should not be linear and may not be even monotonic.
 A measure of the information one variable provides on the other is Mutual
 Information.
 Defined as :
\begin_inset Formula 
\[
MI(X,Y)=\sum_{x}\in X\sum_{y}\in Yp(x,y)log\frac{p(x,y)}{p(x)p(y)}
\]

\end_inset

MI quantifies the amount of information that one random variable contains
 about another.
 More specifically, it measures the reduction in uncertainty about one random
 variable given knowledge of the other.
 In our case, the MI of BP and the MIMIC policy was 
\begin_inset Formula $0.801$
\end_inset

, while the MI of BP and the eICU policy was 
\begin_inset Formula $1.147$
\end_inset

, suggesting that for eICU, BP values provided a more significant uncertainty
 reduction regarding the policy (see rnl_results.ipynb notebook for code).
\end_layout

\begin_layout Section
Discussion
\end_layout

\begin_layout Subsection
MICU - SICU Comparision
\end_layout

\begin_layout Standard
As expected, we have seen major differences between the doses given to patients
 with similar MAP.
 In both the KST and Permutations test, most groups had significant differences,
 apart from the bin which didn't have enough samples - 
\begin_inset Formula $\left(0,49\right)$
\end_inset

, and bins near the target value.
 This finding supports previous research on sepsis treatment variability,
 showing that there is no uniform policy for treatment, even within the
 same hospital.
 Examing the CDF of NOR doses for each MAP group provided additional insights
 to the differences between SICU and MICU, and showed that there is higher
 treatment variability in the MICU on patients with the similar MAP.
 
\end_layout

\begin_layout Standard
It is important to note that the tests split the patients solely on their
 MAP values, and did not split to internal cohorts within each bin.
 It is only natural that patients in SICU and MICU will have different symptoms
 and physiology, and therefore may require different treatment.
 A finer test of treatment variability could have been comparing the decisions
 different doctors made within the same unit, and perfably in treating the
 same patient.
 This could not have been done using MIMIC, as it doesn't hold any data
 on the doctor who made the desicion.
 
\end_layout

\begin_layout Standard
The high variability in sepsis treatment, even within the same hospital,
 indicates potential for the effectiveness of an AI-based model.
 Such model will not be limited to the treating expirence a single human
 clinican can obtain in a lifetime, and could make desicion based on huge
 train datasets.
 
\end_layout

\begin_layout Subsection
RNL
\end_layout

\begin_layout Standard
We've estabilshed a simple, short-term RNL model, looking to stabilize a
 patient near the target MAP value of 65.
 Training the model on MIMIC data provided poor results, which did not pass
 the reasonability test.
 The model makes the Markovian assumption, which likely does not hold in
 low time resolution data like MIMIC (BP mesaurement every hour).
 However, training the model on the eICU data, which had a higher time resolutio
n (mesaurement every 5 min on average) showed much more plausible results,
 and generated a better Mutual Information between the BP and Policy recommended
 dose.
\end_layout

\begin_layout Standard
The initial target of our study was to preform behavioral analysis - find
 out what is the target MAP that doctors in different units aim to.
 In this study we found that 
\series bold
in order to learn
\series default
 
\series bold
behaviors, we need a close temporal resolution 
\series default
- between the MAP value observed and the desicion (NOR dose) that followed.
 As a proof of this, we showed that learning from a higher resolution data
 gives more plausible policies.
 
\end_layout

\begin_layout Standard
Focusing on a short-term model holds potential for clincal applications.
 It uses the key factor crucial for maintaining the patient alive in the
 state of Septic shock - the MAP, and could be relevant to situations where
 only the short goal of stabilizing the patient is important.
 Simple models are also easier to train, as the state space 
\begin_inset Formula $\mathcal{S}$
\end_inset

 is smaller (
\begin_inset Formula $\mathcal{S}$
\end_inset

 grows exponentially with each variable added).
\end_layout

\begin_layout Subsection
Conclusions Based on the Results
\end_layout

\begin_layout Standard
In conclusion, there is evidence for differences in sepsis treatment patterns
 between MICU and SICU units.
 A necessary condition for creating a baseline AI model that is able to
 recommend sepsis treatment regimes is to have a high temporal resolution
 between observations (MAP measurements) and desicions (NOR injections).
\end_layout

\begin_layout Standard
In this regard, eICU is more suited for the task than MIMIC, as the temporal
 resolution it provides is higher.
 An indicator for this is the much more plausible results obtained when
 training the RNL model on the eICU data.
 Creating a MAP stabilizing AI-model holds potential for improving the treatment
 given to sepsis patients at ICUs.
\end_layout

\begin_layout Subsection
Limitations
\end_layout

\begin_layout Enumerate

\series bold
Markovian Assumtpion
\series default
: the model assumed the Markovity of the decision process.
 Although simplifying, this isn't an unreasonable assumption: the half life
 of NOR is about a minute, so the decisions' results are instant.
 However, as discussed before,
\series bold
 this only holds if the data reflects this time resolution
\series default
.
\end_layout

\begin_layout Enumerate

\series bold
Patient filtering:
\series default
 We filtered patients with comorbidities as well as patients with vasopressor
 medcine overlaps (see 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Patients-Filters"
plural "false"
caps "false"
noprefix "false"

\end_inset

), to prevent biases in decision-making (change of dose decision that was
 triggered by a different medicine in effect).
 In a practical setting this assumption will not hold.
 
\end_layout

\begin_layout Enumerate

\series bold
Patient Simulation: 
\series default
As discussed, we trained the model 
\shape italic
in-silico
\shape default
.
 The patient simulation did not limit the trajectory to an actual patient,
 but used bins of all the patients in the data.
 Thus, the simulator was invariant to the fact that observations came from
 different patients, but only took their MAP bin into account.
 Thus the simulator could have also been biased by patients with a lot of
 measurements.
 
\end_layout

\begin_layout Enumerate

\series bold
Reward function:
\series default
 Our reward function was a symmetric 
\begin_inset Formula $\ell_{2}$
\end_inset

 distance from the target value of 65 MAP.
 In practice, no such equilibrium exists: MAP values of 45 and 85 are very
 different from a clinical standpoint and should not be rewarded equally.
 
\begin_inset CommandInset label
LatexCommand label
name "enu:Reward-function:-Our"

\end_inset


\end_layout

\begin_layout Subsection
Future Work
\end_layout

\begin_layout Standard
The model is far from being clinically relevant and applicable.
 A crucial first step will be to compare the model's suggestions on actual
 patients to the decisions made by a clinician, and check if they are within
 a reasonable range.
 Next, one should dive into the areas of disagreement between the clinician
 and the AI, and use the hindsight test to verify who was right (e.g - AI
 suggested higher dose, the patient's BP did not rise, clinician had to
 adjust and vice-versa).
 
\end_layout

\begin_layout Standard
In addition, several important adjustments are required: 
\end_layout

\begin_layout Enumerate

\series bold
Adding variables to the model :
\end_layout

\begin_deeper
\begin_layout Enumerate
Add the fluids the patient receives as an additional variable.
\end_layout

\begin_layout Enumerate
Take comorbidities into account (as well as other medicines that are taken
 simultaneously).
\end_layout

\end_deeper
\begin_layout Enumerate

\series bold
Markovian Relaxation
\series default
: Consider taking several MAP entries back, not just most recent.
 Doing so could relax the strong Markovian assumption.
 
\end_layout

\begin_layout Enumerate

\series bold
Fine-tune the RNL hyperparameters
\series default
: Number of Episodes, 
\begin_inset Formula $\gamma$
\end_inset

 (discount factor), 
\begin_inset Formula $\varepsilon$
\end_inset

 (percentage of explorative decisions in the training phases).
\end_layout

\begin_layout Enumerate

\series bold
Smooth Sampling in Simulation
\series default
.
 During simulation phase, instead of sampling from patients with the exact
 same bins, consider sampling from all bins, only with lower probability.
\end_layout

\begin_layout Enumerate

\series bold
Different reward function
\series default
.
 We choose for simplicity a symmetric 
\begin_inset Formula $\ell_{2}$
\end_inset

 distance from 65, which limits the model (see 
\begin_inset CommandInset ref
LatexCommand ref
reference "enu:Reward-function:-Our"
plural "false"
caps "false"
noprefix "false"

\end_inset

).
 A more accurate reward function should be defined to better reflect the
 clincian's point of view in terms of which MAP value is the most stable.
 
\end_layout

\begin_layout Enumerate

\series bold
Termination conditions
\series default
: Terminate patients simulation that reach unreasonable MAP values, not
 only based on the data.
\end_layout

\begin_layout Enumerate

\series bold
Modern Neural Network Architecture: 
\series default
The model could be reshaped to match the modern NN approaches for handling
 sequential data - the Transformer model.
 It could include attention (for faster computations) and long term memory,
 which could also help to relax the Markovian assumption.
\end_layout

\begin_layout Standard
After a stable model passes the human comparision test, it could be used
 for behavioral analysis.
 In particular, Inverse RNL: Inferring which target values achieve the most
 reward, which is relevant in understanding the current treatment patterns
 used in practice.
 
\end_layout

\begin_layout Section
Resources and Methods
\end_layout

\begin_layout Subsection
Preprocessing
\end_layout

\begin_layout Standard
In order to work nimbly, we created a subset of the relevant data from all
 the possible data that MIMIC-IV offers.
 The subset was creaded by applying the following folters:
\end_layout

\begin_layout Subsubsection
Patients Filters
\begin_inset CommandInset label
LatexCommand label
name "subsec:Patients-Filters"

\end_inset


\end_layout

\begin_layout Enumerate

\series bold
Sepsis ICD codes
\series default
 - Keep only the following ICD (International Classification of Disease)
 codes:
\end_layout

\begin_deeper
\begin_layout Itemize
99592 - Severe sepsis, ICD version 9
\end_layout

\begin_layout Itemize
99591 - sepsis, ICD version 9
\end_layout

\begin_layout Itemize
R652 - Severe sepsis, ICD vesion 10
\end_layout

\begin_layout Itemize
R6520 - Severe sepsis without septic shock, ICD version 10
\end_layout

\begin_layout Itemize
R6521 - Severe sepsis with septic shock, ICD version 10
\end_layout

\end_deeper
\begin_layout Enumerate

\series bold
Age
\series default
 - Keep only patients between ages 20 to 90.
\end_layout

\begin_layout Subsubsection
Stays Filters
\end_layout

\begin_layout Enumerate

\series bold
Unit
\series default
 - Keep only stays that start and end in the same unit.
\end_layout

\begin_layout Enumerate

\series bold
Length
\series default
 - Keep only stays of at least one day.
\end_layout

\begin_layout Subsubsection
Chart Events Filters
\end_layout

\begin_layout Enumerate

\series bold
HR and BP events
\series default
 - Keep only the events of blood pressure and heart rate, with the following
 MIMIC codes:
\end_layout

\begin_deeper
\begin_layout Itemize
225312 - ART BP Mean 
\end_layout

\begin_layout Itemize
220052 - Arterial Blood Pressure mean 
\end_layout

\begin_layout Itemize
220181 - Non Invasive Blood Pressure mean 
\end_layout

\begin_layout Itemize
220045 - Heart Rate
\end_layout

\end_deeper
\begin_layout Subsubsection
Input 
\begin_inset CommandInset label
LatexCommand label
name "subsec:Input-Events-Filters"

\end_inset

Events Filters
\end_layout

\begin_layout Enumerate
Norepinephrine and its alternatives:
\end_layout

\begin_deeper
\begin_layout Itemize
221906 - Norepinephrine
\end_layout

\begin_layout Itemize
221662 - Dopamine
\end_layout

\begin_layout Itemize
221289 - Epinephrine
\end_layout

\begin_layout Itemize
221749 - Phenylephrine
\end_layout

\begin_layout Itemize
229617 - Epinephrine
\end_layout

\begin_layout Itemize
229630 - Phenylephrine (50/250) 
\end_layout

\begin_layout Itemize
229631 - Phenylephrine (200/250)_OLD_1
\end_layout

\begin_layout Itemize
229632 - Phenylephrine (200/250)
\end_layout

\begin_layout Itemize
229789 - Phenylephrine (Intubation)
\end_layout

\begin_layout Itemize
222315 - Vasopressin
\end_layout

\end_deeper
\begin_layout Subsubsection
Interim summary of data filters
\end_layout

\begin_layout Standard
By applying all the filters we got 754 MB that we could load into the memory
 freely instead of 70 GB of MIMIC data.
 
\end_layout

\begin_layout Subsubsection
Decisions Filter
\begin_inset CommandInset label
LatexCommand label
name "subsec:Decisions-Filter"

\end_inset


\end_layout

\begin_layout Standard
The main part of the project is analyzing the decision making of the medical
 teams.
 Since the most important part is the human decision, The idea of decision
 filter is to keep only events of doses that were taken by a medical authority,
 and were not recorded automatically.
 In contrast to the previous filters, in which data was kept because of
 accurate condition that was fulfilled, the case of decisions filter is
 different.
 There is no field in the data that indicates if the dose recorded due to
 a decision of a human or not.
\begin_inset Newline linebreak
\end_inset

Since there is no such field, we need to define what decision is by other
 propereties we do have:
\end_layout

\begin_layout Enumerate

\series bold
FinishedRunning status description
\series default
 - there are 5 status descriptions in the input event files, and one of
 them is 
\begin_inset Quotes eld
\end_inset

FinishedRunning
\begin_inset Quotes erd
\end_inset

.
 by the documentation of MIMIC-IV that status means: 
\begin_inset Quotes eld
\end_inset

The delivery of the item has finished (most frequently, the bag containing
 the compound is empty)
\begin_inset Quotes erd
\end_inset


\begin_inset CommandInset citation
LatexCommand cite
key "mimic-doc"
literal "false"

\end_inset

.
 It infers that those records are not an active decision of a human.
 Deeper investigation of those records shows that indeed the rate of those
 records is not one that human will decide to type manually (like 0.080032155,
 0.10005264, 0.3417207 ).
 Therefore, we defined those doses as non-desicion doses.
\end_layout

\begin_layout Enumerate

\series bold
Short gap between two doses that the first was stopped or paused
\series default
 - there are specific status descriptions in the input event files that
 implies that the dose was paused or stopped by the caretaker.
 Sometimes, there is a record of a successive dose that comes immediately
 after and with same or very close dose rate (for example 0.2 and 1.9999).
 In this case we defined the successive dose as non-decision dose.
\end_layout

\begin_layout Enumerate

\series bold
Successive doses with almost same dose rate - 
\series default
there are cases in which the first dose have an endtime that is the same
 as the starttime of the successive dose, and in addition the dose rate
 is almost the same.
 In those cases we defined the successive dose as non-decision dose.
\end_layout

\begin_layout Subsubsection
Medicine overlap filter
\end_layout

\begin_layout Standard
In many cases a patient get more than one vasopressors simultaneously.
 This situation leads to a difference in the dose rate of Norepinphrine
 between two patients with the same symptoms.
 In order to solve this issue, we filtered out cases in which there are
 overlap between vasopressors.
 The vasopressors that we take into account are the those were mentioned
 previously.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Input-Events-Filters"
plural "false"
caps "false"
noprefix "false"

\end_inset

 
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
key "ICU_SEPS_STATS"
literal "false"

\end_inset

Bennett SR.
 sepsis in the intensive care unit.
 Surgery (Oxf).
 2015 Nov;33(11):565-571.
 doi: 10.1016/j.mpsur.2015.08.002.
 Epub 2015 Oct 9.
 PMID: 32287818; PMCID: PMC7143675.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
key "Sepsis_Mortatlity"
literal "false"

\end_inset

Martin CM, Priestap F, Fisher H, Fowler RA, Heyland DK, Keenan SP, Longo
 CJ, Morrison T, Bentley D, Antman N; STAR Registry Investigators.
 A prospective, observational registry of patients with severe sepsis: the
 Canadian sepsis Treatment and Response Registry.
 Crit Care Med.
 2009 Jan;37(1):81-8.
 doi: 10.1097/CCM.0b013e31819285f0.
 PMID: 19050636.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
key "Gold_standard"
literal "false"

\end_inset

Dugar S, Choudhary C, Duggal A.
 sepsis and septic shock: Guideline-based management.
 Cleve Clin J Med.
 2020 Jan;87(1):53-64.
 doi: 10.3949/ccjm.87a.18143.
 Epub 2020 Jan 2.
 PMID: 31990655.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
key "Sepsis_Treatment_Variability"
literal "false"

\end_inset

Bray A, Kampouraki E, Winter A, Jesuthasan A, Messer B, Graziadio S.
 High Variability in sepsis Guidelines in UK: Why Does It Matter? Int J
 Environ Res Public Health.
 2020 Mar 19;17(6):2026.
 doi: 10.3390/ijerph17062026.
 PMID: 32204395; PMCID: PMC7142432.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
key "Nature_Komorowski"
literal "false"

\end_inset

Komorowski M, Celi LA, Badawi O, Gordon AC, Faisal AA.
 The Artificial Intelligence Clinician learns optimal treatment strategies
 for sepsis in intensive care.
 Nat Med.
 2018 Nov;24(11):1716-1720.
 doi: 10.1038/s41591-018-0213-5.
 Epub 2018 Oct 22.
 PMID: 30349085.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
key "clinician_review"
literal "false"

\end_inset

Jeter, R., Josef, C., Shashikumar, S., & Nemati, S.
 (2019).
 Does the" Artificial Intelligence Clinician" learn optimal treatment strategies
 for sepsis in intensive care?.
 arXiv preprint arXiv:1902.03271.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
key "MIMIC-III"
literal "false"

\end_inset

Johnson, A.
 E.
 W., Pollard, T.
 J., Shen, L., Lehman, L.
 H., Feng, M., Ghassemi, M., Moody, B., Szolovits, P., Celi, L.
 A., & Mark, R.
 G.
 (2016).
 MIMIC-III, a freely accessible critical care database.
 Scientific Data, 3, 160035.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
key "MIMIC-IV"
literal "false"

\end_inset

Johnson, A., Bulgarelli, L., Pollard, T., Horng, S., Celi, L.
 A., & Mark, R.
 (2022).
 MIMIC-IV (version 2.1).
 PhysioNet.
 https://doi.org/10.13026/rrgf-xw32.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
key "eICU"
literal "false"

\end_inset

The eICU Collaborative Research Database, a freely available multi-center
 database for critical care research.
 Pollard TJ, Johnson AEW, Raffa JD, Celi LA, Mark RG and Badawi O.
 Scientific Data (2018).
 DOI: http://dx.doi.org/10.1038/sdata.2018.178.
 Available from: https://www.nature.com/articles/sdata201817
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
key "mimic-doc"
literal "false"

\end_inset

MIMIC-IV documentation.
 Note: https://mimic.mit.edu/docs/iv/modules/icu/inputevents/
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
key "MICU_VS_SICU_SEP"
literal "false"

\end_inset

Toufen C Jr, Franca SA, Okamoto VN, Salge JM, Carvalho CR.
 Infection as an independent risk factor for mortality in the surgical intensive
 care unit.
 Clinics (Sao Paulo).
 2013;68(8):1103-8.
 doi: 10.6061/clinics/2013(08)07.
 PMID: 24037005; PMCID: PMC3752640.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
key "RL Sutton Barto"
literal "false"

\end_inset

Sutton, R.
 S., & Barto, A.
 G.
 (2018).
 Reinforcement learning: An introduction.
 MIT press.
 
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
key "offline_RNL"
literal "false"

\end_inset

Levine, S., Kumar, A., Tucker, G., & Fu, J.
 (2020).
 Offline Reinforcement Learning: Tutorial, Review, and Perspectives on Open
 Problems.
 ArXiv, abs/2005.01643.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
key "skow-github"
literal "false"

\end_inset

Skow, Colin, Coding Demos from the School of AI's Move37 Course https://github.co
m/colinskow/move37.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
key "markov_lme"
literal "false"

\end_inset

Carnegie Malon University, Cosma Shalizi, Statistics 36-462, Spring 2009,
 Lecture 6 https://www.stat.cmu.edu/~cshalizi/462/lectures/06/markov-mle.pdf
\end_layout

\end_body
\end_document
